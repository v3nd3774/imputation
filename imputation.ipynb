{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Iris dataset random classifier & Logistic classifier\n",
    "\n",
    "The purpose of this section is to get a baseline for how performance looks on the classification task with the unmodified Iris dataset. We will be randomly losing data in this dataset at varying percentages and using various imputation strategies to compare and see what the performance implications are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7dcb159262bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menable_iterative_imputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.experimental'"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading that raw data into a `raw_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.DataFrame.from_dict({**{feature:list(map(lambda row: row[idx], iris[\"data\"])) \n",
    "                              for idx, feature in enumerate(iris[\"feature_names\"])},\n",
    "                               **{\"class\":iris[\"target\"]}})\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "X_raw, y_raw = raw_df.iloc[:,0:-1], raw_df.iloc[:,-1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=random.randint(1,101)\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) # Scaler was fit on the training data only\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy & Logistic Regression $F_1$ scores with `100.0%` of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "random_baseline = DummyClassifier()\n",
    "random_baseline.fit(X_train, y_train)\n",
    "y_test_hat = random_baseline.predict(X_test)\n",
    "from sklearn.metrics import f1_score\n",
    "scores = pd.DataFrame(data=[f1_score(y_test, y_test_hat, average='weighted')],\n",
    "                      index=[100.0],\n",
    "                      columns=[\"dummy\"])\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\")\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_hat = clf.predict(X_test)\n",
    "scores['logisticreg'] = pd.Series([f1_score(y_test, y_test_hat, average='weighted')],\n",
    "                                  index=[100.0])\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we continue with the notebook, we will fill up this dataframe with the result of varying levels of random data-loss (`80.0%` indicates that we draw from a uniform distribution of all elements in `X` and randomly keep `80%` of values, discarding `20%`.\n",
    "\n",
    "### Dummy & Logistic Regression $F_1$ scores with `99.0%` of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "def drop_percentage(df, p):\n",
    "    new_df = df.copy()\n",
    "    for i, j in itertools.product(*map(lambda dx: range(dx), df.shape)):\n",
    "        if np.random.rand(1)[0] < p: new_df[i,j] = np.nan\n",
    "    return new_df\n",
    "def percentages(): return np.arange(0.75,1,0.01)\n",
    "X_train_percentage = {\n",
    "    percentage:{\"dirty\":drop_percentage(X_train, percentage)} for percentage in percentages()\n",
    "}\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "for percentage in percentages():\n",
    "    def get_dirty_data(): return X_train_percentage[percentage][\"dirty\"]\n",
    "    imp_mean = SimpleImputer().fit(get_dirty_data())\n",
    "    imp_iter = IterativeImputer().fit(get_dirty_data())\n",
    "    X_train_percentage[percentage][\"clean\"] = {\n",
    "        \"mean\":imp_mean.transform(get_dirty_data()),\n",
    "        \"iter\":imp_iter.transform(get_dirty_data())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
